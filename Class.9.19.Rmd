---
title: "Data Manipulation"
output: html_document
---

```{r}
library(tidyverse)
library(readxl)
library(haven)
```

Let's import the 'FAS_litters.csv' csv using a relative path.

```{r}
litters_df = 
  read_csv("data/Fas_litters.csv")

litters_df = 
  janitor::clean_names(litters_df)

litters_df

```

Janitor cleans up column names by making lower case and converting to snake case

Let's import the 'FAS_litters.csv' csv using an absolute path.

```{r}
#litters_df = 
  #read_csv("~/Documents/R/Data Science/data_wrangling_1/data/FAS_litters.csv")
```
This line isn't working, come back to it later.

Let's import the 'FAS_pups.csv' csv using a relative path.

```{r}
pups_df = 
  read_csv("data/Fas_pups.csv")

pups_df = 
  janitor::clean_names(pups_df)
```

## Look at data

```{r}
litters_df # prints first 10 rows of data

head(litters_df) # prints first 6 rows of data

tail(litters_df) # prints end of the dataset
```

View the entire dataset

```{r, eval = FALSE}
view(litters_df)
```

Look at a data summary

```{r}
str(litters_df)

skimr::skim(litters_df)
```

## Options in 'read_*'

```{r}
litters_df = 
  read_csv("data/FAS_litters.csv")
#automatically assumes first row is column names and reads in data accordingly

litters_df = 
  read_csv("data/FAS_litters.csv",
           skip = 10, col_names = FALSE)
#skips first 10 rows, and does not assume first row is column names, R will assign its own names to columns

```

look at NA values

```{r}
litters_df = 
  read_csv("data/FAS_litters.csv",
           na = c("NA",19))
#assigns values as NA and re-codes the  - anywhere that has "NA" or 19 is treated as missing variable
```

Column types

```{r}
litters_df = 
  read_csv("data/FAS_litters.csv",
           col_types = 
             cols(
               Group = col_factor(),
             ))
```

## other file types 

Import a xlsx file first

```{r}
mlb_df = 
  read_excel("data/mlb11.xlsx")

mlb_df
```

Import a sas file

```{r}
pulse_df = 
  read_sas("data/public_pulse_data.sas7bdat")

pulse_df
```

## Base R 

don't ever use read.csv, only read_csv

```{r, eval = FALSE}
litters_df = 
  read.csv("data/FAS_litters.csv")
```

## Export data

We have code that "cleans" data and need to export it.

```{r}
litters_df_cleaned = 
  read_csv("data/FAS_litters.csv")

litters_df_cleaned = 
  janitor::clean_names(litters_df_cleaned)

write_csv(litters_df_cleaned, "data/litters_cleaned.csv")
```

Date: 21Sept2023
Import FAS litters and pups.

```{r}
litters_df = 
  read.csv("data/FAS_litters.csv")
litters_df = 
  janitor::clean_names(litters_df)

pups_df = 
  read.csv("data/FAS_pups.csv")
pups_df = 
  janitor::clean_names(pups_df)

select(litters_df, group ,litter_number, gd0_weight) #will select defined columns and organize into new dataframe

select(litters_df, group, gd0_weight:gd_of_birth)

select(litters_df, group, starts_with("pups")) #selects all columns that start with pups

select(litters_df, -litter_number) #removes litter number

select(litters_df, -starts_with("gd")) #removes all columns that start with gd

select(litters_df, group, litter_id = litter_number) #rename litter number to litter id

select(litters_df, group, litter_id = litter_number, everything()) # everything keeps all the other columns that                                                                      weren't mentioned

select(litters_df, gd0_weight, everything()) # everything can help reorder columns
```

select vs pull
select will always give dataframe
pull will create a vector, pulls column out of dataframe so that it no longer exists in that dataframe

```{r}
select(litters_df, group)
pull(litters_df, group)
```

Learning Assessment:
In the pups data, select the columns containing litter number, sex, and PD ears.

```{r}
select(pups_df, litter_number, sex, pd_ears)
```

